network:
    name: 'transformer'
    device: 'cuda'
    use_amp: False
    test_model: '14_06_2024_17_31_sl_5000_CUDA.pth'

    transformer:
        name: 'transformer'
        n_head: 4
        n_embd: 4
        n_enc_layer: 12
        mlp_size: 128
        embd_drop: 0
        resid_drop: 0
        att_drop: 0.5
        n_classes: 1

    optimizer:
        name: 'adam'
        beta1: 0.9
        beta2: 0.99
        lr: 1e-3

    loss:
        name: 'l1'

    accuracy:
        epsilon: 0.01


dataset:
    label: sl
    flag: True
    EMA: 200
    normalization: True
    vers: 1
    data_file_name: 'data_v2'
    candle_count: 50
    patch_size: 50

    train_loader:
        epochs: 5000
        num_workers: 0
        batch_size: 25
        shuffle: True
        drop_last: True
        start: 200
        stop: 450

    additional_loader:
        epochs: 75
        step: 1
        num_workers: 0
        batch_size: 25
        shuffle: True
        drop_last: False
        start: 450
        stop: 500

    test_loader:
        num_workers: 0
        batch_size: 1
        shuffle: False
        drop_last: False
        start: 400
        stop: 500

